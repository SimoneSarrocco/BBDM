# Latent Brownian Bridge Diffusion Model Template(Latent Space)
runner: "BBDMRunner"
training:
  n_epochs: 4000
  n_steps: 3960000
  save_interval: 10
  sample_interval: 10
  validation_interval: 1
  accumulate_grad_batches: 4

testing:
  clip_denoised: False
  sample_num: 170

data:
  dataset_name: 'data'
  dataset_type: 'custom_aligned'
  dataset_config:
    dataset_path: '/home/simone.sarrocco/thesis/project/models/diffusion_model/BBDM/data'
    image_size: 496
    channels: 1
    to_normal: False
    transform: True
    resize: False
    gaussian_noise: False
    clip: False
    blur: False
  train:
    batch_size: 1
    shuffle: True
  val:
    batch_size: 1
    shuffle: False
  test:
    batch_size: 1
    shuffle: False

model:
  model_name: "LBBDM-latest-10th" # part of result path
  model_type: "LBBDM" # specify a module
  latent_before_quant_conv: False
  normalize_latent: False
  only_load_latent_mean_std: False
  # model_load_path: '/home/simone.sarrocco/thesis/project/models/diffusion_model/BBDM/results/data/LBBDM-latest-8th/checkpoint/latest_model_90.pth' # model checkpoint path
  # optim_sche_load_path: '/home/simone.sarrocco/thesis/project/models/diffusion_model/BBDM/results/data/LBBDM-latest-8th/checkpoint/latest_optim_sche_90.pth' # optimizer scheduler checkpoint path

  EMA:
    use_ema: True
    ema_decay: 0.995
    update_ema_interval: 8 # step
    start_ema_step: 30000

  CondStageParams:
    n_stages: 2  # this has to be equal to the number of downsampling layers, because at every stage we downsize the conditioning image by half
    in_channels: 1  # input channels is 1 because the input image is the original conditioning image in the pixel space
    out_channels: 8  # output channels is 32 because it has to match the latent dimension in order to then concatenate it to the latent encoding of x

  VQGAN:
    params:
      ckpt_path: '/home/simone.sarrocco/thesis/project/models/diffusion_model/GenerativeModels/tutorials/generative/2d_vqgan/vqgan-2layers-embeddim-8-num-embed-16384/checkpoints/vqgan_best_checkpoint.ckpt' # '/home/simone.sarrocco/thesis/project/models/diffusion_model/GenerativeModels/tutorials/generative/2d_vqgan/vqgan-2layers-embeddim-32-num-embed-16384/checkpoints/vqgan_epoch_50.ckpt'
      embed_dim: 8 # 32
      n_embed: 16384 # 16384
      ddconfig:
        double_z: false
        z_channels: 8 # 32
        resolution: 512
        in_channels: 1
        out_ch: 1
        ch: 128 # 128
        ch_mult: !!python/tuple
          - 2
          - 4
        num_res_blocks: 2
        attn_resolutions: [ ]
        dropout: 0.0

      lossconfig:
        target: torch.nn.Identity  # vqperceptual.VQLPIPSWithDiscriminator

  BB:
    optimizer:
      weight_decay: 0.0
      optimizer: 'Adam'
      lr: 2.e-5
      beta1: 0.9

    lr_scheduler:
      factor: 0.5
      patience: 3000
      threshold: 0.0001
      cooldown: 3000
      min_lr: 5.e-7

    params:
      mt_type: 'linear' # options {'linear', 'sin'}
      objective: 'grad' # options {'grad', 'noise', 'ysubx'}
      loss_type: 'l2' # options {'l1', 'l2'}

      skip_sample: True
      sample_type: 'linear' # options {"linear", "sin"}
      sample_step: 200

      num_timesteps: 1000 # timesteps
      eta: 1.0 # DDIM reverse process eta
      max_var: 1.0 # maximum variance

      UNetParams:
        image_size: 128 # 64
        in_channels: 8 # 32
        model_channels: 256
        out_channels: 8 # 32
        num_res_blocks: 2
        attention_resolutions: !!python/tuple
          - 128
          - 64
          - 32
        channel_mult: !!python/tuple
          - 1
          - 2
          - 4
          - 8
        conv_resample: False
        dims: 2
        num_heads: 8
        num_head_channels: 64
        use_scale_shift_norm: True
        resblock_updown: False
        use_spatial_transformer: False
        context_dim:
        condition_key: "nocond" # options {"SpatialRescaler", "first_stage", "nocond"}